{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1083da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    d_model:int\n",
    "    d_vocab:int\n",
    "    d_hidden:int\n",
    "    max_seq_len:int\n",
    "    numTrans:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bfaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(config.d_model, config.d_hidden)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(config.d_hidden, config.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc2(self.act(self.fc1(x)))\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.Wqk = nn.Parameter(torch.rand(config.d_model, config.d_model))\n",
    "        self.Wov = nn.Parameter(torch.rand(config.d_model, config.d_model))\n",
    "\n",
    "        mask = torch.triu(torch.ones(config.max_seq_len, config.max_seq_len),diagonal=1)\n",
    "        mask = mask.masked_fill(mask==1, -float('inf'))\n",
    "        self.register_buffer(\"M\", mask)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        T = x.size(0)\n",
    "        temp = x @ self.Wqk @ x.T + self.M[:T, :T]\n",
    "        scores = torch.softmax(temp, dim=1)\n",
    "\n",
    "        scores = scores @ x @ self.Wov\n",
    "\n",
    "        return scores\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.attn = Attention(config)\n",
    "        self.mlp = MLP(config)\n",
    "        self.ln1 = nn.LayerNorm(config.d_model)\n",
    "        self.ln2 = nn.LayerNorm(config.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_norm = self.ln1(x)\n",
    "        attn_out = self.attn(x_norm)\n",
    "        x = x+attn_out\n",
    "        x_norm = self.ln2(x)\n",
    "        mlp_out = self.mlp(x_norm)\n",
    "        x = x+mlp_out\n",
    "        return x\n",
    "    \n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embedding = nn.Embedding(config.d_vocab, config.d_model)\n",
    "        self.tbs = nn.ModuleList([Transformer(config) for i in range(self.config.numTrans)])\n",
    "        self.lm_head = nn.Linear(config.d_model, config.d_vocab)\n",
    "\n",
    "    def forward(self, x_tokens):\n",
    "        x = self.embedding(x_tokens)\n",
    "        temp = x\n",
    "        for i in range(self.config.numTrans):\n",
    "            temp = self.tbs[i](temp)\n",
    "\n",
    "        logits = self.lm_head(temp)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d0a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/1342/1342-0.txt\" # Just a demo dataset, we can think about more creative datasets.\n",
    "r = requests.get(url)\n",
    "text = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00a8ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7030\n"
     ]
    }
   ],
   "source": [
    "text = text.lower().replace(\"\\n\", \" \")\n",
    "tokens = text.split()\n",
    "tokens = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "vocab = list(set(tokens))\n",
    "vocab.sort()\n",
    "\n",
    "token2id = {token: idx for idx, token in enumerate(vocab)}\n",
    "id2token = {idx: tok for tok, idx in token2id.items()}\n",
    "\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3179ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128769\n"
     ]
    }
   ],
   "source": [
    "config = Config(d_model=512, d_vocab=len(vocab), d_hidden=256, max_seq_len=2048, numTrans=10)\n",
    "\n",
    "token_ids = [token2id[tok] for tok in tokens]\n",
    "\n",
    "print(len(token_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58428f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 512])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 6287 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(logits.shape)\n\u001b[32m     11\u001b[39m targets = y_ids\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m loss = \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m optimizer.zero_grad()\n\u001b[32m     14\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amsba\\Desktop\\Coding\\Class\\LLMs\\a1_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amsba\\Desktop\\Coding\\Class\\LLMs\\a1_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amsba\\Desktop\\Coding\\Class\\LLMs\\a1_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1362\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m   1361\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs the forward pass.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1363\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1364\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1367\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amsba\\Desktop\\Coding\\Class\\LLMs\\a1_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:3504\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3503\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3506\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3507\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3508\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# pyrefly: ignore [bad-argument-type]\u001b[39;49;00m\n\u001b[32m   3509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3512\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: Target 6287 is out of bounds."
     ]
    }
   ],
   "source": [
    "model = LanguageModel(config)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for step in range(1000):\n",
    "    start = np.random.randint(0, len(token_ids) - config.max_seq_len - 1)\n",
    "    x_ids = torch.tensor(token_ids[start:start+config.max_seq_len])\n",
    "    y_ids = torch.tensor(token_ids[start+1:start+config.max_seq_len+1])\n",
    "    logits = model(x_ids)\n",
    "    targets = y_ids\n",
    "    loss = loss_fn(logits, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        print(f\"Step {step}: Loss is {loss.item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ba629",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_tokens = 50\n",
    "prompt_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a1-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
